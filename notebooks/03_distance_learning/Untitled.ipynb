{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9a141d-9b7e-45da-8e78-466eb5ea6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import japanize_matplotlib\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from albumentations import ImageOnlyTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingLR,\n",
    "    CosineAnnealingWarmRestarts,\n",
    "    MultiStepLR,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import faiss\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "from src.const import OUTPUT_ROOT, DATA_ROOT, QUERY_IMAGES_PATH, CITE_IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c210abca-7006-4f18-9cd1-2796d984a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    competition = \"sake\"\n",
    "    name = \"meigara_classification_with_arcface\"\n",
    "\n",
    "    debug = False\n",
    "\n",
    "    training = True\n",
    "    evaluation = True\n",
    "    embedding = True\n",
    "\n",
    "    seed = 8823\n",
    "    n_fold = 5\n",
    "    trn_fold = [0,1,2,3,4]\n",
    "\n",
    "    target_columns = [\"meigara_label\"]\n",
    "    size = 512\n",
    "\n",
    "    model_name = \"tf_efficientnet_b0_ns\"\n",
    "    max_epochs = 5\n",
    "    train_batch_size = 16\n",
    "    valid_batch_size = 64\n",
    "    num_workers = 4\n",
    "    gradient_accumulation_steps = 1\n",
    "    clip_grad_norm = 1000\n",
    "\n",
    "    optimizer = dict(\n",
    "        optimizer_name=\"AdamW\",\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-2,\n",
    "        eps=1e-6,\n",
    "        beta=(0.9, 0.999),\n",
    "        encoder_lr=1e-4,\n",
    "        decoder_lr=1e-4,\n",
    "    )\n",
    "\n",
    "    scheduler = dict(\n",
    "        scheduler_name=\"cosine\",\n",
    "        num_warmup_steps_rate=0,\n",
    "        num_cycles=0.5,\n",
    "    )\n",
    "    batch_scheduler = True\n",
    "\n",
    "\n",
    "if Config.debug:\n",
    "    Config.max_epochs = 2\n",
    "    Config.n_fold = 2\n",
    "    Config.trn_fold = [0, 1]\n",
    "    Config.name = Config.name + \"_debug\"\n",
    "    Config.size = 128\n",
    "    Config.train_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f6f71d-b412-46ca-9fb2-fb984fa196b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "HOME = OUTPUT_ROOT / 'train_arcface'\n",
    "EXP_NAME = Config.name\n",
    "INPUTS = DATA_ROOT  # input data\n",
    "OUTPUTS = HOME / \"outputs\"\n",
    "INTERMIDIATES = HOME / \"intermidiates\"  # intermidiate outputs\n",
    "SUBMISSIONS = HOME / \"submissions\"\n",
    "OUTPUTS_EXP = OUTPUTS / EXP_NAME\n",
    "EXP_MODELS = OUTPUTS_EXP / \"models\"\n",
    "EXP_REPORTS = OUTPUTS_EXP / \"reports\"\n",
    "EXP_PREDS = OUTPUTS_EXP / \"predictions\"\n",
    "\n",
    "CITE_IMAGES = CITE_IMAGES_PATH\n",
    "QUERY_IMAGES = QUERY_IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c99783-55dd-4e30-8cf0-0b103cdbd717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilaritySearcher:\n",
    "    def __init__(self, embeddings):\n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(self.dimension)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        self.index.add(embeddings)  # type:ignore\n",
    "\n",
    "    def search(self, queries, k=10):\n",
    "        assert queries.shape[1] == self.dimension, \"Query dimensions should match embeddings dimension.\"\n",
    "        faiss.normalize_L2(queries)\n",
    "        D, I = self.index.search(queries, k)  # type:ignore\n",
    "        return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9d7d45a-fcf6-4608-a531-9e1497796bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_features = joblib.load(EXP_PREDS / \"cite_embeddings.pkl\")[\"embeddings_list\"]\n",
    "query_features = joblib.load(EXP_PREDS / \"test_embeddings.pkl\")[\"embeddings_list\"]\n",
    "\n",
    "ave_cite_feature = np.hstack(cite_features)\n",
    "ave_query_feature = np.hstack(query_features)\n",
    "\n",
    "searcher = SimilaritySearcher(ave_cite_feature.astype(np.float32))\n",
    "D, I = searcher.search(ave_query_feature.astype(np.float32), k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f12edc5-3860-42fa-8e19-871ef595fdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109481, 2560)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_cite_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f762aa3e-7afb-4602-9e0f-a88e77b1df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_label(train_df) -> pd.DataFrame:\n",
    "    le = LabelEncoder()\n",
    "    train_df[\"brand_id_label\"] = le.fit_transform(train_df[\"brand_id\"])\n",
    "    train_df[\"meigara_label\"] = le.fit_transform(train_df[\"meigara\"])\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def make_filepath(input_df):\n",
    "    def join_path(dirpath, filename):\n",
    "        return (dirpath / filename).as_posix()\n",
    "\n",
    "    output_df = input_df.assign(\n",
    "        filepath=input_df[\"filename\"].apply(\n",
    "            lambda x: join_path(QUERY_IMAGES, x) if str(x)[0] == \"2\" else join_path(CITE_IMAGES, x)\n",
    "        )\n",
    "    )\n",
    "    return output_df\n",
    "\n",
    "def make_label_dict(train_df):\n",
    "    MLABEL2MEIGARA = train_df[[\"meigara\", \"meigara_label\"]].set_index(\"meigara_label\").to_dict()[\"meigara\"]\n",
    "    BLABEL2BLAND = train_df[[\"brand_id\", \"brand_id_label\"]].set_index(\"brand_id_label\").to_dict()[\"brand_id\"]\n",
    "    return MLABEL2MEIGARA, BLABEL2BLAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7763285c-6da8-45f7-b34f-94d31fd34d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108160, 7)\n"
     ]
    }
   ],
   "source": [
    "# load raw data\n",
    "train_df = pd.read_csv(INPUTS / \"train.csv\")\n",
    "test_df = pd.read_csv(INPUTS / \"test.csv\")\n",
    "cite_df = pd.read_csv(INPUTS / \"cite.csv\").rename(columns={\"cite_gid\":\"gid\", \"cite_filename\":\"filename\"})\n",
    "sample_submission_df = pd.read_csv(INPUTS / \"sample_submission.csv\")\n",
    "\n",
    "if Config.debug:\n",
    "    train_df = train_df.sample(1000, random_state=Config.seed).reset_index(drop=True)\n",
    "    cite_df = cite_df.sample(100, random_state=Config.seed).reset_index(drop=True)\n",
    "\n",
    "# make label\n",
    "train_df = make_train_label(train_df)\n",
    "MLABEL2MEIGARA, BLABEL2BLAND = make_label_dict(train_df)\n",
    "TARGET_DIM = 512  # arcfaceの埋め込み次元\n",
    "\n",
    "# make filepath\n",
    "train_df = make_filepath(train_df)\n",
    "test_df = make_filepath(test_df)\n",
    "cite_df = make_filepath(cite_df)\n",
    "\n",
    "# for submission\n",
    "IDX2CITE_GID = cite_df.to_dict()[\"gid\"]\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca6f8734-a811-4b40-8882-5cd923eac700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(indices):\n",
    "    vfunc = np.vectorize(lambda x: IDX2CITE_GID[x])\n",
    "    gid_array = vfunc(I)\n",
    "    submission_df = test_df[[\"gid\"]].assign(cite_gid=[\" \".join(list(x)) for x in gid_array.astype(str)])\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3edf1e22-f65f-4f3f-8f60-4c1853f71a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission_df = make_submission(indices=I)\n",
    "submission_df.to_csv(SUBMISSIONS / f\"{Config.name}_hstack.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baff1c-f2e2-4ec0-b668-7ee7289e559e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
